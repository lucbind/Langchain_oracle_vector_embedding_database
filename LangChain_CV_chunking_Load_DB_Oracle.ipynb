{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src=\"./chunking.png\" width=\"200\"></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CV Chunking PDF Docuemnts, Load in dataabse Prompt RAG question \n",
    "sono configurati diversi metodi di chunking riferiemnto \n",
    "https://towardsdatascience.com/how-to-chunk-text-data-a-comparative-analysis-3858c4a0997a\n",
    "\n",
    "* Spacy Sentence Splitter \n",
    "* Langchain Character Text Splitter  \n",
    "* NLTK Sentence Tokenizer "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pacchetti da installare "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install PyPDF2 nltk pydantic langchain langchain==0.0.349 spacy oracledb sentence_transformers sklearn.cluster python-dotenv time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python3 -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install ./drivers/oracledb-2.0.0.dev20231121-cp311-cp311-macosx_10_9_universal2.whl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fine pacchetti da installare"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cartella con pdf dei CV\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = './docs/CV_PDF'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Variabili di ambiente \n",
    "creare un file .env in questa cartella seguendo il formato TOML con le variabili e salvarlo \n",
    "CO_API_KEY=\"\"\n",
    "USERNAME=\"\"\n",
    "PASSWORD=\"\"\n",
    "HOST=\"\"\n",
    "PORT=\"\"\n",
    "SERVICE_NAME=\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "import os\n",
    "\n",
    "# leggi il valore delle variabile d'ambiente \n",
    "cohere_api_key =os.environ.get('CO_API_KEY') #keep your cohere api key  port  in the .env file and retrieve it\n",
    "oracle_service_name =os.environ.get('SERVICE_NAME') #keep your oracle listner port  in the .env file and retrieve it\n",
    "oracle_user = os.environ.get('USERNAME') #keep your oracle username in the .env file and retrieve it\n",
    "oracle_password =os.environ.get('PASSWORD') #keep your oracle usernamepassword in the .env file and retrieve it\n",
    "oracle_hostname =os.environ.get('HOST') #keep your oracle server hostname in the .env file and retrieve it\n",
    "oracle_port =os.environ.get('PORT') #keep your oracle listner port  in the .env file and retrieve it\n",
    "\n",
    "#verifica\n",
    "#print (oracle_service_name,cohere_api_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cohere Api key "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cohere\n",
    "co = cohere.Client(cohere_api_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Oracle enviroment "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import oracledb\n",
    "# Connect to your Oracle 23.4 database\n",
    "#print (oracle_user, oracle_password,oracle_hostname,oracle_port,oracle_service_name)\n",
    "connection = oracledb.connect(\n",
    "    user=oracle_user,\n",
    "    password=oracle_password,\n",
    "    dsn=oracle_hostname+\":\"+oracle_port+\"/\"+oracle_service_name\n",
    "    )\n",
    "cursor = connection.cursor()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drop and create table Vector_CV_PDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "cursor.execute(\"\"\"\n",
    "    begin\n",
    "        execute immediate 'drop table Vector_CV_PDF';\n",
    "        exception when others then if sqlcode <> -942 then raise; end if;\n",
    "    end;\"\"\")\n",
    "# Create table Vector_TEST1\n",
    "cursor.execute(\"\"\"\n",
    "    create table Vector_CV_PDF (\n",
    "        id_pdf number,\n",
    "        id_chunk number,\n",
    "        nome_file varchar2(300),       \n",
    "        v vector(1024, float32),\n",
    "        chunk varchar2(4000),\n",
    "        primary key (id_pdf,id_chunk))\"\"\")\n",
    "\n",
    "#v vector(384, float32) --> 384 e' la dimensione"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Funzione per estrarre i file PDF  all'interno della cartella fornita"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def elenca_files_con_percorsi(carta):\n",
    "    lista_files = []\n",
    "    for cartella_radice, sottocartelle, files in os.walk(carta):\n",
    "        for file in files:\n",
    "            if file.lower().endswith('.pdf'):  # Verifica se il file ha estensione PDF\n",
    "                  percorso_completo = os.path.join(cartella_radice, file)\n",
    "                  lista_files.append(percorso_completo)\n",
    "    return lista_files\n",
    "#print (len(lista_file))\n",
    "#print (lista_file)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Funzione per convertire pdf to testo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PyPDF2 import PdfReader\n",
    "# Extracting Text from PDF\n",
    "def extract_text_from_pdf(file_path):\n",
    "    with open(file_path, 'rb') as file:\n",
    "        pdf = PdfReader(file)\n",
    "        text = \" \".join(page.extract_text() for page in pdf.pages)\n",
    "        \n",
    "    return text\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spacy\n",
    "Funzione per suddivisione in chunk mediante spacy del testo , tennde a creare piccoli chiuck in confronto con  Langchain Character Text Splitter, . Puo essere vantaggioso con piccoli testi "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "# chuk Text using spacy \n",
    "def divide_in_frase(testo):\n",
    "    nlp = spacy.load('en_core_web_sm')\n",
    "    doc = nlp(testo)\n",
    "    frasi = list(doc.sents)\n",
    "    return frasi\n",
    "#testo_da_dividere = \"Questo è un esempio di testo. Può contenere più di una frase. SpaCy è uno strumento di elaborazione del linguaggio naturale.\"\n",
    "#frasi_divise = divide_in_frase(testo_da_dividere)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Langchain Character Text Splitter\n",
    "RecursiveCharacterTextSplitter ricorsivamente divide il testo sulla base di specifici caratteri .\n",
    "Puo essere vantaggioso con Testi generici"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "def custom_text_splitter(text, chunk_size=100, chunk_overlap=10):\n",
    "    splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=chunk_size,\n",
    "        chunk_overlap=chunk_overlap,\n",
    "        length_function=len,\n",
    "    )\n",
    "    \n",
    "    chunks = splitter.create_documents([text])\n",
    "    return chunks\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLTK Sentence Tokenizer\n",
    "Il Natural Language Toolkit (NLTK) fornisce una funzione utile per suddividere il testo in frasi. e' un modo semplice ed efficiente per dividere un ampio corpo di testo in singole frasi,ma ha alcune limitazioni:\n",
    "* Dipendenza dalla lingua:Funziona bene con l'inglese ma potrebbe non fornire risultati accurati con altre lingue senza una configurazione aggiuntiva.\n",
    "* Abbreviazioni e punteggiatura: il tokenizzatore può occasionalmente interpretare erroneamente le abbreviazioni o altri segni di punteggiatura.\n",
    "* Mancanza di comprensione semantica: come la maggior parte dei tokenizzatori, il tokenizzatore di frasi NLTK non considera la relazione semantica tra le frasi. Pertanto, un contesto che si estende su più frasi potrebbe andare perso nel processo di tokenizzazione.\n",
    "\n",
    "* nltk.punkt è un modulo di NLTK (Natural Language Toolkit) che fornisce un tokenizer di frasi. Il tokenizer divide un testo in una lista di frasi utilizzando un algoritmo non supervisionato per costruire un modello per le parole di abbreviazione, le collocazioni e le parole che iniziano le frasi.\n",
    "* nltk.corpus: fornisce accesso a una vasta gamma di corpora etichettati e non etichettati, come il corpus Brown, il corpus Penn Treebank, il corpus WordNet e molti altri.\n",
    "* nltk.tokenize: fornisce una serie di tokenizzatori per la suddivisione del testo in parole, frasi e altre unità.\n",
    "* nltk.stem: fornisce una serie di algoritmi di stemming per ridurre le parole alle loro forme di base.\n",
    "* nltk.tag: fornisce una serie di modelli di tagging per l’etichettatura delle parti del discorso, l’etichettatura delle entità denominate e altro ancora.\n",
    "* nltk.chunk: fornisce una serie di modelli di chunking per l’identificazione di frasi nominali, verbi e altre unità sintattiche.\n",
    "* nltk.parse: fornisce una serie di parser per l’analisi sintattica del testo.\n",
    "* nltk.sentiment: fornisce una serie di modelli per l’analisi del sentiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "\n",
    "def split_text_into_sentences(text):\n",
    "    sentences = nltk.sent_tokenize(text)\n",
    "    return sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Confronta i diversi metodi Langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file :  0\n",
      "Spacy Sentence Splitter num chunk  17\n",
      "* Langchain Character Text Splitter num chunk  15\n",
      "NLTK Sentence Tokenizer num chunk  15\n",
      "file :  1\n",
      "Spacy Sentence Splitter num chunk  19\n",
      "* Langchain Character Text Splitter num chunk  22\n",
      "NLTK Sentence Tokenizer num chunk  16\n",
      "file :  2\n",
      "Spacy Sentence Splitter num chunk  15\n",
      "* Langchain Character Text Splitter num chunk  28\n",
      "NLTK Sentence Tokenizer num chunk  14\n",
      "file :  3\n",
      "Spacy Sentence Splitter num chunk  19\n",
      "* Langchain Character Text Splitter num chunk  22\n",
      "NLTK Sentence Tokenizer num chunk  16\n",
      "file :  4\n",
      "Spacy Sentence Splitter num chunk  14\n",
      "* Langchain Character Text Splitter num chunk  24\n",
      "NLTK Sentence Tokenizer num chunk  13\n"
     ]
    }
   ],
   "source": [
    "id_file=0\n",
    "lista_file= elenca_files_con_percorsi(folder)\n",
    "for nume_file in range(len(lista_file)):\n",
    "    id_file+=1\n",
    "    id_chunk=0\n",
    "    # print (id_nome_file)\n",
    "    # Extract text from the PDF and split it into sentences\n",
    "    nome_file=lista_file[nume_file]\n",
    "    text = extract_text_from_pdf(lista_file[nume_file])\n",
    "    #print (text)\n",
    "    spacy_frasi_divise = divide_in_frase(text)\n",
    "    splitter_result_chunks = custom_text_splitter(text)\n",
    "    nltk_sentences = split_text_into_sentences(text)\n",
    "    print ('file : ', nume_file)\n",
    "    print ('Spacy Sentence Splitter num chunk ',len(spacy_frasi_divise))\n",
    "    print ('* Langchain Character Text Splitter num chunk ',len(splitter_result_chunks))\n",
    "    print ('NLTK Sentence Tokenizer num chunk ',len(nltk_sentences))\n",
    "\n",
    "   # print (spacy_frasi_divise)\n",
    "   # print (splitter_result_chunks)\n",
    "   # print (splitter_result_chunks[0].page_content)\n",
    "   # print (nltk_sentences)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # Implementazione\n",
    " Conversione  di tutti i pdf, della cartella fornita, in text, successivamente suddiviso il testo  in chuck mediante spacy e traformati in vector embedding con Cohere embed , alla fine inseriti all'interno della tabella vector_PDF del database Oracel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numero di chunk per il pdf  :  ./docs/CV_PDF/luca_Migliori.pdf  --  15\n",
      "numero di chunk per il pdf  :  ./docs/CV_PDF/pino_sarsi.pdf  --  16\n",
      "numero di chunk per il pdf  :  ./docs/CV_PDF/Paolo_checchi.pdf  --  14\n",
      "numero di chunk per il pdf  :  ./docs/CV_PDF/eugenio_bernaci.pdf  --  16\n",
      "numero di chunk per il pdf  :  ./docs/CV_PDF/mario_bianchi.pdf  --  13\n",
      "numero documenti pdf totali inseriti :  5\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "id_file=0\n",
    "\n",
    "#definizione type per oracle variabili\n",
    "cursor.setinputsizes(None,None,oracledb.DB_TYPE_VARCHAR, oracledb.DB_TYPE_VECTOR )\n",
    "\n",
    "#definizione del modello utilizzato da cohere e il metodo per l'embedding orientato allo store degli stessi\n",
    "cohere_model_def='embed-english-v3.0'\n",
    "cohere_input_type='search_document'\n",
    "\n",
    "lista_file= elenca_files_con_percorsi(folder)\n",
    "for nume_file in range(len(lista_file)):\n",
    "    id_file+=1\n",
    "    id_chunk=0\n",
    "    # print (id_nome_file)\n",
    "    # Extract text from the PDF and split it into sentences\n",
    "    nome_file=lista_file[nume_file]\n",
    "    text = extract_text_from_pdf(lista_file[nume_file])\n",
    "    #print (text)\n",
    "    #scegliere quale metodo di suddivisione testo utilizzare\n",
    "    #\n",
    "    #frasi_divise = spacy_frasi_divise = divide_in_frase(text)\n",
    "    #frasi_divise = splitter_result_chunks = custom_text_splitter(text)\n",
    "    frasi_divise = nltk_sentences = split_text_into_sentences(text)\n",
    "    # necessario perche su cohere non si possono fare piu di tot chiamate al minuto\n",
    "    api_call=0\n",
    "    for frase in frasi_divise:\n",
    "        api_call+=1\n",
    "        if api_call<90:\n",
    "            id_chunk+=1\n",
    "            response = co.embed(\n",
    "                    #spacy_frasi_divise\n",
    "                    #texts=[frase.text],\n",
    "                    #nltk_sentences\n",
    "                    texts=[frase],\n",
    "                    #splitter_result_chunks\n",
    "                    #texts=[frase non provato non frase[0].page_content\n",
    "                    model=cohere_model_def,\n",
    "                    input_type=cohere_input_type\n",
    "            )\n",
    "            #print (response)\n",
    "            vector_result = response.embeddings[0]\n",
    "            #print (vector_result)\n",
    "            ##print(id_file,nome_file,vector_result,frase)\n",
    "            # Inserimento all'interno di oracle vector db  dell'embedding usando bind variable\n",
    "            cursor.execute(\"insert into Vector_CV_PDF values (:1,:2,:3,:4,:5)\", [id_file,id_chunk,nome_file, vector_result,frase])\n",
    "        else :\n",
    "            api_call=0\n",
    "            # necessario perche su cohere non si possono fare piu di tot chiamate al minuto\n",
    "            time.sleep(60)\n",
    "    print ( 'numero di chunk per il pdf  : ' , nome_file, ' -- ',id_chunk)\n",
    "    connection.commit()\n",
    "\n",
    "print ( 'numero documenti pdf totali inseriti : ' , id_file)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verifica contenuto tabella"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve the vector\n",
    "cursor.execute('select * from  Vector_CV_PDF')\n",
    "#cursor.execute('select max(id_pdf) from  Vector_PDF')\n",
    "for row in cursor:\n",
    "     print(row)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Richiesta al modello e conversione in embedding\n",
    "modificare la domanda a proprio piacimento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cohere.Embeddings {\n",
      "\tembeddings: [[0.02330017, -0.025817871, -0.027694702, -0.06762695, -0.032440186, -0.02798462, -0.04916382, 0.028549194, 0.026916504, 0.09490967, 0.02458191, -0.015838623, 0.0657959, -0.028564453, -0.05368042, 0.04107666, 0.032684326, 0.033813477, 0.048309326, -0.0021190643, -0.014678955, 0.0446167, 0.015945435, -0.031585693, 0.035064697, -0.04373169, -0.06225586, -0.007511139, 0.029129028, 0.02154541, 0.012321472, 0.02848816, 0.009376526, 0.0015449524, -0.007106781, 0.033569336, -0.008132935, 0.00031352043, 0.006122589, 0.0029411316, 0.010818481, -0.0060157776, -0.026107788, -0.026382446, -0.05557251, -0.0069618225, -0.011116028, -0.0021476746, 0.01675415, -0.07354736, 0.009025574, -0.0146484375, 0.047943115, 0.01777649, -0.023223877, 0.025924683, -0.04348755, -0.035369873, 0.015182495, 0.046905518, 0.025360107, -0.0037841797, 0.008613586, -0.018554688, 0.022460938, -0.0024738312, 0.05895996, 0.004676819, 0.04385376, 0.010482788, -0.039794922, 0.029586792, -0.01751709, 0.047576904, 0.0026054382, -0.02658081, 0.03845215, -0.00071525574, 0.0005235672, 0.04876709, 0.0126571655, 0.01473999, -0.025650024, -0.047546387, 0.042663574, -0.0045166016, 0.00012254715, -0.02357483, -0.0043640137, 0.022155762, -0.0040283203, 0.03173828, 0.021957397, 0.05444336, -0.012237549, -0.014701843, 0.040618896, 0.011169434, 0.026184082, 0.020385742, -0.023880005, -0.03744507, 0.018249512, -0.018234253, -0.031982422, 0.04055786, 0.049468994, 0.020996094, 0.014755249, -0.0051994324, -0.018936157, 0.0067634583, -0.047088623, -0.08728027, -0.027557373, 0.07751465, -0.005355835, -0.020965576, 0.03866577, -0.03250122, 0.009109497, 0.0026607513, -0.0058059692, 0.03527832, 0.010032654, 0.020523071, -0.035369873, 0.012573242, 0.089416504, -0.032958984, -0.009475708, 0.033355713, -0.0413208, -0.019729614, -0.019180298, 0.0037937164, -0.045135498, 0.052581787, 0.012954712, -0.03475952, 0.038848877, -0.00028848648, 0.10876465, 0.045684814, 0.032592773, 0.03778076, 0.038085938, -0.020446777, -0.018585205, 0.0044784546, -0.024536133, 0.026031494, -0.0025615692, 0.029067993, 0.054626465, 0.037597656, 0.033935547, -0.0052833557, -0.007549286, 0.019454956, -0.0072250366, 0.0146865845, 0.027679443, -0.03302002, -0.050079346, -0.03488159, -0.005180359, 0.0045661926, 0.027114868, 0.057373047, -0.027816772, 0.031097412, 0.06976318, 0.013504028, -0.01058197, -0.0023288727, -0.030319214, 0.00017285347, 0.03363037, 0.009063721, 0.0059776306, -0.017059326, 0.05343628, 0.019104004, -0.03994751, -0.016952515, 0.015052795, 0.019134521, 0.045562744, 0.010253906, 0.043792725, -0.022644043, -0.0018415451, -0.049957275, -0.00049352646, -0.011787415, -0.010887146, 0.004219055, -0.014846802, 0.059143066, 0.01713562, 0.029373169, -0.012886047, -0.018844604, -0.053131104, 0.032989502, -0.027191162, 0.027999878, -0.0077056885, 0.009429932, 0.022735596, -0.012313843, -0.012748718, 0.0071487427, 0.001537323, -0.007858276, -0.027313232, 0.0038433075, 0.030349731, -0.04638672, 0.06463623, 0.015167236, 0.047180176, 0.033416748, -0.0073127747, -0.014831543, 0.01108551, 0.0045928955, 0.028442383, 0.0060691833, 0.045166016, -0.04547119, -0.0031337738, -0.016204834, -0.03503418, 0.003730774, -0.020385742, -0.03817749, 0.0026626587, 0.048217773, 0.014984131, 0.012054443, -0.020874023, 0.010803223, 0.07409668, 0.024810791, 0.0020160675, 0.023162842, -0.01083374, 0.015960693, -0.0033721924, -0.015022278, 0.019607544, -0.03729248, -0.026260376, 0.034332275, -0.026779175, 0.0262146, -0.013381958, -0.0061683655, 0.0065345764, 0.007858276, 0.0206604, -0.022140503, -0.04748535, 0.03338623, 0.0043296814, 0.018630981, -0.069885254, 0.010223389, 0.039520264, 0.10211182, -0.008872986, 0.044677734, -0.018966675, -0.015380859, -0.030670166, -0.0024814606, 0.006298065, 0.016662598, 0.010124207, 0.0058021545, 0.028182983, -0.0046081543, 0.05999756, -0.048187256, -0.011444092, -0.019851685, 0.012863159, 0.021224976, 0.040802002, 0.02243042, 0.02947998, -0.0055122375, 0.040252686, -0.018722534, 0.12207031, 0.06890869, -0.037109375, 0.031341553, -0.009269714, 0.002254486, 0.02204895, -0.06964111, -4.2021275e-05, -0.01713562, 0.0016012192, 0.0209198, 0.008865356, -0.09222412, 0.0670166, 0.037200928, 0.020050049, 0.048858643, -0.03741455, -0.03060913, -0.048217773, 0.012901306, -0.02722168, 0.029159546, 0.028274536, -0.04244995, -0.037841797, -0.010284424, -0.036193848, 0.005935669, -0.013038635, -0.006511688, -0.04525757, -0.03866577, 0.021102905, -0.04309082, -0.012489319, -0.002752304, 0.022354126, -0.0041770935, 0.0026130676, 0.016403198, -0.003238678, 0.020721436, 0.025878906, -0.0068740845, 0.033081055, 0.0027656555, -0.05355835, -0.0067329407, -0.014015198, 0.0057907104, -0.057495117, -0.030136108, 0.054656982, -0.01235199, 0.0034942627, 0.010856628, 0.0046844482, -0.016052246, -0.01828003, 0.031158447, -0.0010089874, -0.037994385, 0.008842468, 0.021575928, 0.0063705444, -0.05355835, -0.033203125, -0.047698975, -0.011146545, 0.009666443, -0.004634857, 0.025054932, -0.013442993, -0.0011482239, 0.01977539, -0.010757446, -0.011070251, 0.004760742, 0.039276123, -0.024169922, 0.0014810562, 0.016815186, 0.009391785, 0.036499023, 0.0022468567, 0.040771484, 0.0057525635, -0.012702942, -0.076171875, 0.0019664764, -0.000787735, 0.045410156, -0.0073776245, -0.006389618, -8.404255e-05, 0.0019836426, 0.052124023, -0.0053367615, -0.01977539, 0.055908203, -0.14978027, 0.013282776, 0.020248413, 0.0016403198, 0.025924683, -0.030914307, -0.08465576, 0.061309814, -0.045776367, 0.027618408, 0.019577026, -0.003250122, -0.009155273, -0.053497314, -0.0049934387, -0.06939697, 0.0017910004, -0.01008606, -0.07952881, -0.0035591125, 0.018051147, 0.046966553, -0.028717041, 0.0035362244, -0.04269409, 0.022125244, -0.024307251, 0.004753113, 0.013710022, 0.040100098, -0.001247406, -0.027359009, -0.002254486, -0.04309082, -0.026245117, -0.039276123, -0.04345703, -0.00067281723, -0.032043457, 0.0065574646, -0.0024108887, -0.020584106, -0.005077362, -0.0017442703, 0.010688782, 0.021240234, -0.0022830963, 0.0031661987, 0.019485474, -0.02658081, 0.01209259, -0.023208618, 0.024002075, -0.011657715, 0.05810547, 0.011116028, -0.016113281, 0.016296387, 0.053985596, 0.021530151, -0.007987976, 0.049804688, 0.01713562, -0.0052108765, -0.0003874302, -0.01890564, -0.01007843, 0.05279541, -0.029891968, 0.014808655, -0.0463562, 0.006832123, 0.030075073, -0.014831543, -0.021362305, -0.023864746, 0.03768921, -0.022460938, -0.013877869, 0.0004992485, -0.009750366, 0.0038642883, 0.0060043335, 0.013793945, 0.0045661926, -0.027328491, -0.018249512, 0.014457703, -0.055480957, -0.028366089, -0.015090942, 0.020523071, -0.015411377, 0.0029792786, 0.008522034, -0.014961243, -0.041809082, 0.0025463104, -0.021560669, 0.042785645, 0.012283325, -0.03982544, -0.019210815, -0.019470215, 0.056640625, 0.04421997, -0.0028133392, 0.017501831, -0.00044965744, 0.029846191, 0.038391113, -0.021011353, 0.016418457, -0.0075531006, -0.05718994, -0.0008301735, -0.054473877, 0.021270752, 0.0031833649, -0.054718018, 0.008712769, 0.012802124, -0.0026569366, -0.025482178, 0.010192871, 0.01713562, 0.019714355, 0.029953003, -0.048309326, 0.049621582, -0.058013916, 0.023666382, 0.0039863586, 0.0524292, 0.013061523, -0.04473877, 0.043945312, -0.05041504, 0.018341064, -0.026275635, -0.01133728, 0.047973633, -0.013542175, -0.037597656, 0.0010328293, 0.017684937, -0.021850586, 0.009117126, -0.05178833, 0.033996582, 0.088256836, 0.027557373, 0.0020828247, -0.04171753, -0.028396606, -0.011077881, 0.0041923523, -0.0793457, -0.044067383, 0.012687683, -0.011489868, 0.021087646, -0.013023376, 0.019851685, 0.005874634, -0.00013697147, -0.030944824, 0.007293701, 0.010467529, 0.0036411285, 0.025100708, -0.03439331, -0.020095825, -0.03451538, 0.0021362305, 0.01625061, -0.009063721, 0.018875122, 0.007888794, -0.014930725, 0.0061149597, -0.014801025, -0.015556335, 0.019699097, 0.021331787, -0.00055885315, 0.0057640076, -0.010299683, 0.0284729, 0.0031108856, -0.009925842, -0.022445679, -0.0259552, -0.011451721, 0.014755249, -0.040283203, -0.03970337, -0.013618469, 0.008522034, 0.0057754517, -0.01184082, -0.017486572, 0.036743164, 0.015007019, 0.015419006, -0.009994507, 0.0017309189, 0.021530151, 0.05545044, 0.023513794, -0.030471802, -0.0036907196, 0.026184082, 0.03265381, -0.012527466, -0.017471313, 0.0041160583, -0.01637268, 0.018127441, -0.03491211, -0.0022621155, -0.024002075, 0.03225708, 0.007003784, 0.021224976, 0.07684326, -0.023254395, 0.02923584, 0.004776001, -0.034698486, -0.040100098, 0.033721924, -0.060546875, -0.00034928322, -0.032348633, -0.03265381, -0.009017944, 0.005264282, -0.025680542, -0.005771637, -0.00017285347, -0.02670288, 0.0069770813, -0.034362793, -0.015029907, -0.013427734, 0.020141602, -0.042236328, 0.019424438, 0.04598999, -0.028579712, -0.06008911, 8.773804e-05, -0.00289917, -0.010696411, 0.012382507, 0.030029297, -0.03466797, -0.0048103333, 0.025115967, -0.022644043, -0.040649414, 0.01600647, 0.027923584, -0.009353638, 0.005241394, 0.0076904297, 0.060821533, 0.049072266, 0.053955078, -0.017684937, -0.0046844482, 0.009101868, 0.056427002, 0.00982666, -0.007030487, -0.010177612, 0.026153564, -0.017105103, 0.0068359375, -0.017532349, 0.031829834, 0.0014820099, 0.039154053, 0.014671326, 0.0138549805, -0.05657959, -0.006942749, -0.017684937, 0.029083252, 0.050567627, -0.037017822, -0.03540039, -0.043304443, 0.016296387, -0.08306885, 0.022018433, 0.05517578, -0.051635742, -0.035217285, 0.0129470825, 0.01008606, -0.012702942, -0.018554688, 0.018371582, -0.049224854, -0.014328003, 0.024917603, -0.0017910004, 0.030441284, -0.05041504, -0.008422852, -0.010612488, 0.044830322, 0.085998535, 0.0059432983, 0.049346924, -0.022857666, -0.020767212, -0.062164307, -0.10913086, 0.021224976, -0.013755798, 0.02041626, -0.002067566, -0.052764893, 0.010955811, -0.03036499, -0.028076172, -0.0067100525, 0.026046753, 0.029708862, 0.030960083, -0.014480591, 0.0010967255, 0.0043411255, 0.004463196, 0.008857727, -0.020355225, 0.04977417, 0.009468079, -0.041412354, -0.041259766, -0.026000977, 0.02607727, 0.016845703, 0.024368286, 0.08898926, 0.041259766, 0.05117798, -0.031402588, 0.03652954, -0.048187256, 0.010726929, -0.018157959, -0.014503479, -0.0135269165, 0.01398468, 0.062561035, -0.013427734, -0.042175293, -0.012489319, -0.015396118, 0.018463135, 0.014907837, 0.00077819824, -0.0044784546, 0.064208984, 0.0002772808, -0.00078487396, 0.021621704, -0.021957397, -0.013595581, 0.027191162, -0.008636475, -0.0102005005, -0.00422287, -0.0099487305, 0.026992798, -0.0029029846, -0.018997192, -0.045288086, -0.024124146, -0.013572693, 0.038879395, 0.032226562, 0.0019330978, 0.043823242, 0.013504028, 0.00932312, 0.011474609, 0.022613525, -0.039031982, 0.029052734, 0.005508423, 0.0061683655, 0.014671326, 0.01158905, -0.007396698, -0.008522034, 0.033447266, -0.0069770813, 0.02458191, -0.082458496, 0.036590576, -0.04562378, 0.02267456, -0.05215454, 0.0052757263, 0.0065345764, -0.04647827, -0.03717041, 0.0096206665, -0.054534912, 0.008682251, 0.0029850006, 0.019042969, -0.012863159, -0.006668091, 0.018234253, 0.0011968613, -0.055603027, -0.021209717, 0.0368042, 0.003435135, -0.012252808, 0.032958984, -0.015052795, 0.017074585, -0.036743164, 0.057556152, -0.0063323975, -0.034942627, 0.007205963, -0.011070251, 0.0031852722, 0.055908203, 0.007522583, -0.017791748, -0.023025513, 0.03189087, -0.0069236755, 0.009239197, -0.007587433, 0.021209717, -0.012893677, 0.022598267, 0.032409668, 0.016113281, -0.016799927, -0.05014038, -0.0016908646, 0.047058105, 0.0025043488, 0.010635376, 0.015930176, 0.024276733, -0.021102905, 0.0033550262, -0.052947998, 0.0058174133, -0.006427765, -0.036315918, 0.01423645, -0.043792725, -0.021606445, 0.021530151, 0.0026664734, 0.02520752, -0.0067443848, 0.013847351, 0.00042939186, 0.02305603, -0.0362854, -0.0069999695, -0.07043457, -0.033203125, -0.0099487305, 0.0012607574, -0.058288574, -0.018737793, -0.0028896332, 0.058258057, 0.007820129, 0.029876709, -0.050079346, -0.003414154, 0.034942627, 0.030181885, 0.05709839, 0.0357666, -0.029525757, 0.028015137, 0.007144928, -0.0010023117, 0.043304443, 0.009376526, 0.003534317, -0.018920898, 0.0057678223, -0.014518738, 0.0040779114, -0.035064697, -0.007724762, -0.011512756, -0.00046801567, 0.051727295, 0.008979797, -0.029190063, -0.05609131, 0.042816162, -0.02192688, -0.016036987, 0.058624268, 0.018051147, 0.049926758, 0.00932312, -0.038970947, -0.0005259514, -0.011993408, 0.045043945, -0.076660156, -0.014297485, 0.025756836, -0.009994507, 0.004638672, -0.041625977, 0.0011816025, -0.0496521, -0.0063705444, 0.0149002075, -0.031585693, -0.008766174, -0.030197144, -0.011932373, 0.105895996, 0.0072135925, -0.007545471, 0.0002989769, 0.004840851, -0.00687027, -0.007904053, -0.0073928833, -0.001619339, 0.006958008, 0.0057373047, -0.011360168, -0.0052375793, 0.053955078, -0.02154541, 0.0050811768, 0.0005135536, 0.046875, -0.020812988, 0.012702942, 0.016052246, -0.006252289, 0.054992676, -0.022415161, 0.006462097, -0.051239014, -0.036895752, -0.012290955, -0.011184692, -0.024795532, 0.014259338, 0.020248413, 0.06976318, 0.0057029724, -0.05279541, 0.010353088, -0.016174316, 0.009422302, -0.032073975, -0.02798462, -0.018814087, 0.0062294006, 0.004108429, 0.0052452087, 0.013389587, 0.00919342, -0.0056991577, -0.010238647, 0.020828247, 0.0015764236, -0.055267334, 0.0023593903, 0.0925293, -0.056152344, -0.012611389, 0.012588501, 0.003189087, 0.02470398, -0.032592773, -0.033477783, -0.017211914, -0.020401001, 0.023269653, -0.023162842, 0.021392822, -0.024383545, 0.0014858246, -0.020980835, 0.0101623535, -0.017196655, 0.013671875, 0.029922485, 0.020645142, 0.011428833, 0.07720947, -0.032409668, 0.011268616, -0.02305603, 0.033813477, -0.042114258, 0.0029754639, 0.0052871704, -0.027023315, 0.021255493, -0.0051994324, -0.004676819, -0.029251099, -0.01676941, 0.12609863, -0.008972168, 0.01927185]]\n",
      "\tcompressed_embeddings: []\n",
      "\tmeta: {'api_version': {'version': '1'}, 'billed_units': {'input_tokens': 32}}\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "#usiamo la chiamata a cohere per trasformare la domanda in vettori \n",
    "#usiamo lo stesso modello ma con una tipologia differente orientata alla ricerca\n",
    "prompt_question = \"I've opened a new position for an Italian coding expert in Taleo application , in the meantime could you providing internal name showing me the highlights of this person\"\n",
    "response = co.embed(\n",
    "        texts=[prompt_question],\n",
    "        model='embed-english-v3.0',\n",
    "        input_type='search_query'\n",
    ")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ricerca dei chunk nel vector db con il vettore KNN piu vicino "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ricerca all'intenro del database oracle sfruttando l'operatore VECTOR_DISTANCE\n",
    "import array\n",
    "from typing import List\n",
    "vector_prompt:List[float]=response.embeddings[0]\n",
    "\n",
    "cursor = connection.cursor()\n",
    "sql = \"\"\"SELECT CHUNK  from Vector_CV_PDF where (ID_PDF, id_chunk) in \n",
    "(\n",
    "select ID_PDF ,substr(ranking,instr(ranking,'-',-1)+1)chunk_id from (\n",
    "select ID_PDF , min(ranking) ranking\n",
    "  from (\n",
    "        select ID_PDF,VECTOR_DISTANCE(V,:1)||'--'||id_chunk ranking \n",
    "          from Vector_CV_PDF  \n",
    "        order by VECTOR_DISTANCE(V,:2)\n",
    "        )\n",
    "group by id_pdf order by 2,1 desc FETCH FIRST 3 ROWS ONLY\n",
    ")\n",
    ")\"\"\"\n",
    "\n",
    "sql = \"\"\"SELECT CHUNK  from Vector_CV_PDF where (ID_PDF, id_chunk) in \n",
    "(\n",
    "select ID_PDF ,substr(ranking,instr(ranking,'-',-1)+1)chunk_id from (\n",
    "select ID_PDF , min(ranking) ranking\n",
    "  from (\n",
    "        select ID_PDF,VECTOR_DISTANCE(V,:1)||'--'||id_chunk ranking \n",
    "          from Vector_CV_PDF  \n",
    "        order by VECTOR_DISTANCE(V,:2)\n",
    "        )\n",
    "group by id_pdf order by 2,1 desc FETCH FIRST 3 ROWS ONLY\n",
    ")\n",
    ")\"\"\"\n",
    "\n",
    "with connection.cursor() as cursor:\n",
    "        array_query1 = array.array(\"d\", vector_prompt)\n",
    "        array_query2 = array.array(\"d\", vector_prompt)\n",
    "        cursor.execute(sql,[array_query1,array_query1])\n",
    "        rows = cursor.fetchall()\n",
    "#print(rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Funzione cohere per generare testo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creiamo una funzione per  cohere  per generae la risposta\n",
    "def generate_text(prompt, temp=0):\n",
    "  response = co.generate(\n",
    "    model='command',\n",
    "    prompt=prompt,\n",
    "    max_tokens=200,\n",
    "    temperature=temp)\n",
    "  return response.generations[0].text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Genera risposta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Your text contains a trailing whitespace, which has been trimmed to ensure high quality generations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Based on the provided information, here are the internal names and role highlights for the three candidates:\n",
      "\n",
      "1. Paolo Cecchi (Cloud Interconnect Specialist)\n",
      "   - Internal Name: PCI (Paolo Cecchi Interconnect)\n",
      "   - Professional Highlights:\n",
      "     - Experienced Cloud Interconnect Specialist with a proven track record of designing and implementing robust cloud connectivity solutions.\n",
      "     - Expertise in network architecture and cloud computing, with a focus on providing secure and reliable connections between different cloud platforms.\n",
      "     - Strong problem-solving and analytical skills, with the ability to find creative solutions to complex technical challenges.\n",
      "     - Excellent communication and collaboration skills, with a ability to work effectively with cross-functional teams to achieve project goals.\n",
      "\n",
      "2. Eugenio Bernaci (Cloud Specialist)\n",
      "   - Internal Name: EB (Eugenio Bernaci)\n",
      "   - Professional Highlights:\n",
      "     - Born in 1970 and raised in Rome, with a strong background in cloud computing and IT infrastructure.\n",
      "     - Experience in designing and\n"
     ]
    }
   ],
   "source": [
    "# richiamiamo la funzione per generare la risposta passando con i chunk ottenuti dal database Oracle\n",
    "\n",
    "text_prompt ='Kindly answer the following question  ' + prompt_question  + ' based on  ' ;\n",
    "for i in range(len(rows)):\n",
    "    text_prompt += rows[i][0]+' and  '\n",
    "\n",
    "#print (text_prompt)\n",
    "\n",
    "\n",
    "\n",
    "response = generate_text(text_prompt, temp=0.5)\n",
    "print(response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
